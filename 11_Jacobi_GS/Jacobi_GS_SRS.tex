\documentclass[final,5p]{elsarticle}

% \documentclass[preprint,12pt]{elsarticle}

%% Use the option review to obtain double line spacing
%% \documentclass[authoryear,preprint,review,12pt]{elsarticle}

%% Use the options 1p,twocolumn; 3p; 3p,twocolumn; 5p; or 5p,twocolumn
%% for a journal layout:
% \documentclass[final,1p,times]{elsarticle}
%% \documentclass[final,1p,times,twocolumn]{elsarticle}
% \documentclass[final,3p,times]{elsarticle}
%% \documentclass[final,3p,times,twocolumn]{elsarticle}
% \documentclass[final,5p,times]{elsarticle}
%% \documentclass[final,5p,times,twocolumn]{elsarticle}
\usepackage[portuguese]{babel}

%% For including figures, graphicx.sty has been loaded in
%% elsarticle.cls. If you prefer to use the old commands
%% please give \usepackage{epsfig}

%% The amssymb package provides various useful mathematical symbols
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{multirow}
\usepackage{tabularx}

\usepackage{pgfplots}
\pgfplotsset{compat=1.18}
\usepgfplotslibrary{statistics}
\usepackage{pgfplotstable}

\usepackage{placeins}
\usepackage{hyperref}
\numberwithin{equation}{section}

\usepackage{algorithm}
\usepackage[noEnd=true, indLines=true]{algpseudocodex}
\algrenewcommand\algorithmicrequire{\textbf{Entrada:}}
\algrenewcommand\algorithmicwhile{\textbf{Enquanto}}
\algrenewcommand\algorithmicrepeat{\textbf{Repete}}
\algrenewcommand\algorithmicuntil{\textbf{Até}}
\algrenewcommand\algorithmicif{\textbf{Se}}
\algrenewcommand\algorithmicthen{\textbf{então}}
\algrenewcommand\algorithmicelse{\textbf{Caso contrário}}
\algrenewcommand\algorithmicensure{\textbf{Objetivo:}}
\algrenewcommand\algorithmicreturn{\textbf{Retorna:}}
\algrenewcommand\algorithmicdo{\textbf{faça}}
\algrenewcommand\algorithmicforall{\textbf{Para todos}}
\algnewcommand{\LineComment}[1]{\State \(\triangleright\) \textcolor{black!50}{\emph{#1}}}

\newcommand*{\squareb}{\textcolor{black}{\rule{0.5em}{0.5em}}}
\newcommand*{\squareg}{\textcolor{gray}{\rule{0.5em}{0.5em}}}

% \usepackage[fleqn]{nccmath}
% \usepackage{multicol}


%=========== Gloabal Tikz settings
% \pgfplotsset{compat=newest}
% \usetikzlibrary{math}
% \pgfplotsset{
%     height = 10cm,
%     width = 10cm,
%     tick pos = left,
%     legend style={at={(0.98,0.30)}, anchor=east},
%     legend cell align=left,
%     }
%  \pgfkeys{
%     /pgf/number format/.cd,
%     fixed,
%     precision = 1,
%     set thousands separator = {}
% }

%% The amsthm package provides extended theorem environments
%% \usepackage{amsthm}

%% The lineno packages adds line numbers. Start line numbering with
%% \begin{linenumbers}, end it with \end{linenumbers}. Or switch it on
%% for the whole article with \linenumbers.
%% \usepackage{lineno}

\usepackage{listings}
\usepackage{xcolor}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.98,0.98,0.98}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,
    breaklines=true,
    captionpos=b,
    keepspaces=true,
    numbers=left,
    numbersep=5pt,
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    tabsize=2
}

\lstset{style=mystyle}

% \journal{Nuclear Physics B}

\begin{document}

\begin{frontmatter}

%% Title, authors and addresses

%% use the tnoteref command within \title for footnotes;
%% use the tnotetext command for theassociated footnote;
%% use the fnref command within \author or \address for footnotes;
%% use the fntext command for theassociated footnote;
%% use the corref command within \author for corresponding author footnotes;
%% use the cortext command for theassociated footnote;
%% use the ead command for the email address,
%% and the form \ead[url] for the home page:
%% \title{Title\tnoteref{label1}}
%% \tnotetext[label1]{}
%% \author{Name\corref{cor1}\fnref{label2}}
%% \ead{email address}
%% \ead[url]{home page}
%% \fntext[label2]{}
%% \cortext[cor1]{}
%% \affiliation{organization={},
%%             addressline={},
%%             city={},
%%             postcode={},
%%             state={},
%%             country={}}
%% \fntext[label3]{}

\title{Performance dos Métodos Jacobi, Gauss-Siedel e SRS para Resolver Sistemas de Equações de Problemas de Fluxo em Meio Poroso Incompressíveis\tnoteref{label_title}}
\tnotetext[label_title]{Relatório número 11 como parte dos requisitos da disciplina IM253: Métodos Numéricos para Fenômenos de Transporte.}

%% use optional labels to link authors explicitly to addresses:
%% \author[label1,label2]{}
%% \affiliation[label1]{organization={},
%%             addressline={},
%%             city={},
%%             postcode={},
%%             state={},
%%             country={}}
%%
%% \affiliation[label2]{organization={},
%%             addressline={},
%%             city={},
%%             postcode={},
%%             state={},
%%             country={}}

\author{Tiago C. A. Amorim\fnref{label_author}}
\tnotetext[label_author]{Atualmente cursando doutorado no Departamento de Engenharia de Petróleo da Faculdade de Engenharia Mecânica da UNICAMP (Campinas/SP, Brasil).}
\ead{t100675@dac.unicamp.br}
\affiliation[Tiago C. A. Amorim]{organization={Petrobras},%Department and Organization
addressline={Av. Henrique Valadares, 28},
city={Rio de Janeiro},
postcode={20231-030},
state={RJ},
country={Brasil}}

\begin{abstract}

        Uma simulação de fluxo em meio poroso demanda a resolução de grandes sistemas de equações não-lineares a cada passo de tempo. Em geral estes sistemas são resolvidos com métodos que fazem a resolução de sucessivos sistemas de equações lineares. Este trabalho avaliou a utilização de métodos iterativos na resolução de problemas de fluxo em meio poroso incompressível. Os Métodos de Jacobi, Gauss-Seidel e SRS tiveram performance pior que a do Método de Eliminação de Gauss, e se mostraram inadequados para o problema proposto.

\end{abstract}


%%Graphical abstract
% \begin{graphicalabstract}
%\includegraphics{grabs}
% \end{graphicalabstract}

%%Research highlights
% \begin{highlights}
% \item Research highlight 1
% \item Research highlight 2
% \end{highlights}

\begin{keyword}
    Método de Eliminação de Gauss \sep Método de Jacobi \sep Método de Gauss-Siedel \sep Método SRS \sep Fluxo em Meio Poroso
%% keywords here, in the form: keyword \sep keyword

%% PACS codes here, in the form: \PACS code \sep code

%% MSC codes here, in the form: \MSC code \sep code
%% or \MSC[2008] code \sep code (2000 is the default)

\end{keyword}

\end{frontmatter}

%% \linenumbers

%% main text
\section{Introdução}

        Os sistemas de equações lineares que aparecem na resolução de um problema de fluxo em meio poroso em geral são caracterizadas por terem muitas variáveis. É comum os modelos terem mais de 100 mil parâmetros (podendo chegar a alguns milhões). Outra característica é a esparsidade da matriz de coeficientes.

        Este trabalho continua a avaliação de métodos de resolução de sistemas de equações lineares. O estudo anterior verificou que o Método da Eliminação de Gauss gera bons resultados, mas é computacionalmente custoso\cite{relatoriogauss}. Nesta segunda etapa são avaliados três métodos iterativos: Jacobi, Gauss-Siedel e SRS.

\section{Metodologia}

        A descrição do Método de Eliminação de Gauss e do fluxo em meio poroso incompressível foi feita no relatório anterior\cite{relatoriogauss}, e não será repetida neste relatório.

    \subsection{Método de Jacobi}

        Dado um sistema de $n$ equações lineares na forma $\\A \vec{x} = \vec{b}$:

        \begin{align}
            \left[
                \begin{array}{cccc}
                    a_{1,1}    & a_{1,2}    & \ldots & a_{1,n} \\
                    a_{2,1}    & a_{2,2}    & \ldots & a_{2,n} \\
                    \vdots     & \vdots     &        & \vdots  \\
                    a_{n,1}    & a_{n,2}    & \ldots & a_{n,n}
                \end{array}
            \right]
            \begin{bmatrix}
                x_{1}  \\
                x_{2}  \\
                \vdots \\
                x_{n}
            \end{bmatrix}
            =
            \begin{bmatrix}
                b_{1}  \\
                b_{2}  \\
                \vdots \\
                b_{n}
            \end{bmatrix}
            \label{eq:sistema}
        \end{align}

        O Método de Jacobi consiste em, primeiramente, explicitar cada uma das variáveis do sistema de equações ($x_i = f_i(x_1,\ldots,x_{i-1},x_{i+1},\ldots,x_n)$). A partir de uma estimativa inicial ($\vec{x}_0 = \{x_1^0,x_n^0,\ldots,x_n^0\}$) são realizadas sucessivos cálculos com estas funções, até ser atingido algum critério de convergência\cite{burden2016analise}.

        A partir de \ref{eq:sistema} é possível construir equações para cada uma das variáveis do problema da seguinte forma:

        \begin{align}
            x_i = \frac{1}{a_{i,i}} ( b_i - \sum^{n}_{\substack{j=1 \\ j \neq i}} a_{i,j} x_j ) \label{eq:jacobi}
        \end{align}

        Como o termo $a_{i,i}$ aparece no divisor de \ref{eq:jacobi}, é uma condição necessária para o método não existirem valores nulos na diagonal da matriz de coeficientes. Para isso é preciso fazer trocas de linhas. Uma estratégia para melhorar o método é buscar ter valores altos na diagonal, ou buscar colocar valores na diagonal \emph{relativamente} altos com relação aos demais termos da mesma linha (maximizar $\frac{|a_{i,i}|}{\max_j |a_{i,j}|}$).

        O algoritmo de Jacobi é apresentado em \ref{alg:jacobi}.

        \begin{algorithm}
            \caption{Método de Jacobi}\label{alg:jacobi}
            \begin{algorithmic}
                \Require $a_{i,j},\,b_i\,e\, x_i^0\; para \; i=1,2,\ldots,n\,\text{e}\\j=1,2,\ldots,n;\\\epsilon_{conv} > 0\;\text{e}\; k_{max} \in \mathbb{Z}, k_{max} > 0$
                \ForAll{$i \in \{1, \dots, n\}$}
                    \If{$a_{i,i} = 0$}
                        \State \Return Erro: termo nulo na diagonal.
                    \EndIf
                \EndFor
                \State $k \gets 1$
                \While{$k \leq k_{max}$}
                    \ForAll{$i \in \{1, \dots, n\}$}
                        \State $x_i^k \gets \frac{1}{a_{i,i}} ( b_i - \sum^{n}_{\substack{j=1 \\ j \neq i}} a_{i,j} x_j^{k-1} )$
                    \EndFor
                    \If{$||\vec{x}_k - \vec{x}_{k-1}|| < \epsilon_{conv}$}
                        \State \Return $x_i^k \; para \; i=1,2,\ldots,n$
                    \EndIf
                    \State $k \gets k+1$
                \EndWhile
                \State Avisar que método não atingiu convergência
                \State \Return $x_i^k \; para \; i=1,2,\ldots,n$
            \end{algorithmic}
        \end{algorithm}

        Diferentes critérios de convergência podem ser utilizados para definir quando a convergência é atingida. Definindo duas normas: $L^2$ (\ref{eq:normadois}) e $L^\infty$ (\ref{eq:normainf}):

        \begin{align}
            ||x||_2 &:= \sqrt{\sum_{i}x_i^2} \label{eq:normadois} \\
            ||x||_\infty &:= \max_{i} |x_i| \label{eq:normainf}
        \end{align}

        Podemos utilizar diferentes critérios de convergência, como:

        \begin{align}
            \epsilon &= ||x_i^k - x_i^{k-1}||_2 \label{eq:conva} \\
            \epsilon &= ||x_i^k - x_i^{k-1}||_\infty \label{eq:convb} \\
            \epsilon &= \frac{||x_i^k - x_i^{k-1}||_2}{||x_i^k||_2} \label{eq:convc} \\
            \epsilon &= \frac{||x_i^k - x_i^{k-1}||_\infty}{||x_i^k||_\infty} \label{eq:convd} \\
        \end{align}

    \subsection{Método de Gauss-Siedel}

        O Método de Gauss-Siedel parte da ideia do Método de Jacobi, mas utiliza a estimativa \emph{mais atual} de cada variável. Ou seja, ao invés de usar os valores de $x_i^{k-1}$ em cada passo da iteração, é utilizado o valor de $x_i^k$, quando disponível.

        As discussões sobre os termos da diagonal e critérios de convergência feitas para o Método de Jacobi seguem válidas para este método. O algoritmo do método é apresentado em \ref{alg:gausssiedel}.

        \begin{algorithm}
            \caption{Método de Gauss-Siedel}\label{alg:gausssiedel}
            \begin{algorithmic}
                \Require $a_{i,j},\,b_i\,e\, x_i^0\; para \; i=1,2,\ldots,n\,\text{e}\\j=1,2,\ldots,n;\\\epsilon_{conv} > 0\;\text{e}\; k_{max} \in \mathbb{Z}, k_{max} > 0$
                \ForAll{$i \in \{1, \dots, n\}$}
                    \If{$a_{i,i} = 0$}
                        \State \Return Erro: termo nulo na diagonal.
                    \EndIf
                \EndFor
                \State $k \gets 1$
                \While{$k \leq k_{max}$}
                    \ForAll{$i \in \{1, \dots, n\}$}
                        \State $x_i^k \gets \frac{1}{a_{i,i}} ( b_i - \sum^{i-1}_{j=1} a_{i,j} x_j^{k-1} - \sum^{n}_{j=i+1} a_{i,j} x_j^{k})$
                    \EndFor
                    \If{$||\vec{x}_k - \vec{x}_{k-1}|| < \epsilon_{conv}$}
                        \State \Return $x_i^k \; para \; i=1,2,\ldots,n$
                    \EndIf
                    \State $k \gets k+1$
                \EndWhile
                \State Avisar que método não atingiu convergência
                \State \Return $x_i^k \; para \; i=1,2,\ldots,n$
            \end{algorithmic}
        \end{algorithm}

    \subsection{Métodos SRS}

        Podemos calcular o residual da m-ésima variável na k-ésima iteração do Método de Gauss-Siedel como:

        \begin{align}
            r_i^k &= b_i - \sum^{i}_{j=1} a_{i,j} x_j^{k-1} - \sum^{n}_{j=i+1} a_{i,j} x_j^{k} \label{eq:residual}
        \end{align}

        Maniplando \ref{eq:residual} e substituindo na equação de atualização de $x_i$ do Método de Gauss-Siedel, temos:

        \begin{align}
            r_i^k &= b_i - \sum^{i-1}_{j=1} a_{i,j} x_j^{k-1} - \sum^{n}_{j=i+1} a_{i,j} x_j^{k} \nonumber \\
            r_i^k + a_{i,i} x_i^{k-1} &= b_i - \sum^{i-1}_{j=1} a_{i,j} x_j^{k-1} - \sum^{n}_{j=i+1} a_{i,j} x_j^{k} \nonumber \\
            \frac{r_i^k}{a_{i,i}} + x_i^{k-1} &= \frac{1}{a_{i,i}} ( b_i - \sum^{i-1}_{j=1} a_{i,j} x_j^{k-1} - \sum^{n}_{j=i+1} a_{i,j} x_j^{k}) \nonumber \\
            x_i^k &= x_i^{k-1} + \frac{r_i^k}{a_{i,i}} \label{eq:atualizaxi}
        \end{align}

        A equação \ref{eq:atualizaxi} pode ser encarada como uma sequência. Uma forma de ajudar na convergência de ${x_i}$ é aplicar um modificador no termo que atualiza $x_i$:

        \begin{align}
            x_i^k &= x_i^{k-1} + \omega \frac{r_i^k}{a_{i,i}}, \;\text{com} \; \omega > 0 \label{eq:atualizaxiw}
        \end{align}

        Quando $0 < \omega < 1$ temos métodos de sub-relaxação, e quando $\omega > 1$ temos métodos de sobre-relaxação. A equação \ref{eq:atualizaxiw} ainda pode ser manipulada para explicitar $x_i^{k-1}$ do lado direito e chegar ao Método SRS (sobre-relaxação sucessiva):

        \begin{align}
            x_i^k = &(1 - \omega) x_i^{k-1} \nonumber \\
            &+ \omega \frac{1}{a_{i,i}} \left( b_i - \sum^{i-1}_{j=1} a_{i,j} x_j^{k-1} - \sum^{n}_{j=i+1} a_{i,j} x_j^{k} \right) \label{eq:atualizaxisrs}
        \end{align}

        O algoritmo do Método SRS é parecido com o algoritmo de Gauss-Seidel. O algoritimo é apresentado em \ref{alg:srs}.

        \begin{algorithm}
            \caption{Método SRS}\label{alg:srs}
            \begin{algorithmic}
                \Require $a_{i,j},\,b_i\,e\, x_i^0\; para \; i=1,2,\ldots,n\,\text{e}\\j=1,2,\ldots,n;\\\omega > 0,\; \epsilon_{conv} > 0\;\text{e}\; k_{max} \in \mathbb{Z}, k_{max} > 0$
                \ForAll{$i \in \{1, \dots, n\}$}
                    \If{$a_{i,i} = 0$}
                        \State \Return Erro: termo nulo na diagonal.
                    \EndIf
                \EndFor
                \State $k \gets 1$
                \While{$k \leq k_{max}$}
                    \ForAll{$i \in \{1, \dots, n\}$}
                        \State $x_{i,GS} \gets \frac{1}{a_{i,i}} \left( b_i - \sum^{i-1}_{j=1} a_{i,j} x_j^{k-1} - \sum^{n}_{j=i+1} a_{i,j} x_j^{k} \right)$
                        \State $x_i^k \gets (1 - \omega) x_i^{k-1} + \omega x_{i,GS}$
                    \EndFor
                    \If{$||\vec{x}_k - \vec{x}_{k-1}|| < \epsilon_{conv}$}
                        \State \Return $x_i^k \; para \; i=1,2,\ldots,n$
                    \EndIf
                    \State $k \gets k+1$
                \EndWhile
                \State Avisar que método não atingiu convergência
                \State \Return $x_i^k \; para \; i=1,2,\ldots,n$
            \end{algorithmic}
        \end{algorithm}

    \subsection{Problema proposto}

        O problema proposto é a resolução de uma das iterações do Método do Ponto Fixo que foi implementado para resolver um modelo de fluxo em meio poroso incompressível. Foram gerados arquivos com a matriz de coeficientes e o vetor de constantes para dois tipos de modelo (uni e bidimensional) e diferentes refinamentos de malha.

        O relatório anterior\cite{relatoriogauss} descreve em mais detalhes o problema a ser resolvido.

\section{Implementação} \label{sec:implementacao}

        Todo o código utilizado nesta análise foi desenvolvido em C++. As principais funções são:

        \begin{description}
            \item[readCSV] Função que recebe um \emph{string} com o camimnho de um arquivo CSV e faz a sua leitura. É assumido que é utilizado vírgula como separador. A função retorna uma matrix de \emph{double}.
            \item[SolveGauss] Função que recebe uma matriz de \emph{double} e um vetor de \emph{double}, e resolve o sistema de equações lineares usando Eliminação de Gauss com Pivotamento Parcial. Existe a opção de realizar o pivotamento com e sem uso de escala.
            \item[SolveSRS] Função que recebe uma matriz de \emph{double} e um vetor de \emph{double}, e resolve o sistema de equações lineares usando o Método SRS. Ao definir $\omega = 1$ o algoritmo coincide com o Método de Gauss-Siedel. Existe a opção de solicitar que sejam sempre utilizados os valores de $x_j^{k-1}$ nos cálculos de $x_i^{k}$, que junto com $\omega = 1$ leva ao Método de Jacobi.
        \end{description}

\section{Resultados}

        Uma primeira dificuldade encontrada na implementação foi a definição do critério de convergência. Existe uma diferença significativa entre a ordem de grandeza das variáveis do problema proposto (saturações e pressões), de forma que um critério do tipo \ref{eq:convd} não é muito adequado. Foi preciso adotar um critério de convergência ligeiramente diferente dos listados anteriormente. A proposta foi de utilizar o máximo erro relativo por variável:

        \begin{align}
            \epsilon &= \left|\left|\frac{x_i^k - x_i^{k-1}}{x_i^k}\right|\right|_\infty \label{eq:conve}
        \end{align}

        Em \ref{eq:conve} a divisão é feita elemento a elemento (\emph{piecewise}).

        O primeiro teste realizado foi o de verificar a qualidade das respostas das resoluções de diferentes sistemas de equações lineares de modelos unidimensionais. Foi adotado um valor de convergência baixo ($10^{-5}$) e um número máximo iterações alto ($2000$). Foram testados os três métodos expostos, e o Método SRS foi testado com $\omega = 0.8$ e $\omega = 1.2$.

        \begin{figure}[hbt!]
            \begin{tikzpicture}
                \begin{loglogaxis}[
                    grid=both,
                    xlabel = {Número de Parâmetros},
                    ylabel = {$\epsilon$},
                    ymax = 2e-2,
                    legend style={at={(0.50,0.80)}, anchor=east, font=\footnotesize},
                    ]
                    \addplot[color=red, solid, thick, mark=*] table [x=var, y=ConvJac, col sep=comma] {results_1D_2k.csv};
                    \addplot[color=black, solid, thick, mark=*] table [x=var, y=ConvGS, col sep=comma] {results_1D_2k.csv};
                    \addplot[color=blue, solid, thick, mark=*] table [x=var, y=ConvSRS08, col sep=comma] {results_1D_2k.csv};
                    \addplot[color=cyan, solid, thick, mark=*] table [x=var, y=ConvSRS12, col sep=comma] {results_1D_2k.csv};
                    \legend{Jacobi, Gauss-Siedel, SRS $\omega = 0.8$, SRS $\omega = 1.2$};
                \end{loglogaxis}
            \end{tikzpicture}
            \caption{Valor da norma de convergência após até duas mil iterações na resolução de problemas unidimensionais.}
            \label{fig:convergencia2k}
        \end{figure}

        Observa-se na Figura \ref{fig:convergencia2k} que alguns dos métodos não conseguiram atingir o critério de convergência dentro do número de iterações estabelecidas. Foi reaizada uma segunda tentativa, agora com até 10 mil iterações.

        \begin{figure}[hbt!]
            \begin{tikzpicture}
                \begin{loglogaxis}[
                    grid=both,
                    xlabel = {Número de Parâmetros},
                    ylabel = {$\epsilon$},
                    ymax = 2e-2,
                    legend style={at={(0.50,0.80)}, anchor=east, font=\footnotesize},
                    ]
                    \addplot[color=red, solid, thick, mark=*] table [x=var, y=ConvJac, col sep=comma] {results_1D_10k.csv};
                    \addplot[color=black, solid, thick, mark=*] table [x=var, y=ConvGS, col sep=comma] {results_1D_10k.csv};
                    \addplot[color=blue, solid, thick, mark=*] table [x=var, y=ConvSRS08, col sep=comma] {results_1D_10k.csv};
                    \addplot[color=cyan, solid, thick, mark=*] table [x=var, y=ConvSRS12, col sep=comma] {results_1D_10k.csv};
                    \legend{Jacobi, Gauss-Siedel, SRS $\omega = 0.8$, SRS $\omega = 1.2$};
                \end{loglogaxis}
            \end{tikzpicture}
            \caption{Valor da norma de convergência após até dez mil iterações na resolução de problemas unidimensionais.}
            \label{fig:convergencia10k}
        \end{figure}

        Na Figura \ref{fig:convergencia10k} \emph{faltam} marcadores dos resultados com maior número de parâmetros. Vários métodos divergiram nos casos com maior número de parâmetros. Nem mesmo o Método SRS com $\omega = 0.8$ conseguiu gerar resultados para todos os problemas testados, pois divergiu nos testes com 160, 180 e 200 parâmetros.

        \begin{figure}[hbt!]
            \begin{tikzpicture}
                \begin{loglogaxis}[
                    grid=both,
                    xlabel = {Número de Parâmetros},
                    ylabel = {Tempo [$10^{-3}s$]},
                    legend style={at={(0.45,0.80)}, anchor=east, font=\footnotesize},
                    xmin=4,
                    ]
                    \addplot[color=green, solid, thick, mark=*] table [x=var, y=dt, col sep=comma] {results_1D_Gauss.csv};
                    \addplot[color=red, solid, thick, mark=*] table [x=var, y=dtJac, col sep=comma] {results_1D_10k.csv};
                    \addplot[color=black, solid, thick, mark=*] table [x=var, y=dtGS, col sep=comma] {results_1D_10k.csv};
                    \addplot[color=blue, solid, thick, mark=*] table [x=var, y=dtSRS08, col sep=comma] {results_1D_10k.csv};
                    \addplot[color=cyan, solid, thick, mark=*] table [x=var, y=dtSRS12, col sep=comma] {results_1D_10k.csv};
                    \legend{Elim.Gauss, Jacobi, Gauss-Siedel, SRS $\omega = 0.8$, SRS $\omega = 1.2$};
                \end{loglogaxis}
            \end{tikzpicture}
            \caption{Tempo de resolução de problemas unidimensionais.}
            \label{fig:dt10k}
        \end{figure}

        Todos os métodos foram muito rápidos na resolução (convergindo ou divergindo) dos problemas unidimensionais testados, em geral tomando menos de 1 segundo. Na Figura \ref{fig:dt10k} estão os resultados para o limite de 10 mil iterações, e, mesmo sendo um método lento, o Método da Eliminação de Gauss foi o mais rápido. A queda no tempo de resolução de alguns casos é reflexo da divergência das respostas.

        O pacote para Python \emph{Numpy} foi utilizado para resolver os mesmos sistemas de equações\cite{dongarra1992lapack}. Estes resultados foram utilizados como uma aproximação das respostas exatas. Os Gráficos \ref{fig:erropressao10k} e \ref{fig:errosw10k} mostram a máxima diferença absoluta entre os valores \emph{exatos} e os resultados de cada método, para as pressões e saturações das células, respectivamente.

        O Método da Eliminação de Gauss foi ocultado do gráfico de erros na pressão porque seus resultados são muito melhores que os dos outros métodos ($||p_{i,exato}-p_i||_\infty \approx 10^{-10}$). Os demais métodos apresentam uma relação linear entre o logarítmo do número de parâmetros e o logarítmo do erro. Os métodos iterativos tiveram dificuldade para encontrar bons resultados. Os resultados são especialmente ruins para as pressões. Em alguns casos o método da Eliminação de Gauss teve erro zero para as saturação de água, e por isso \emph{faltam} algumas marcas no gráfico semilog.

        \begin{figure}[hbt!]
            \begin{tikzpicture}
                \begin{loglogaxis}[
                    grid=both,
                    xlabel = {Número de Parâmetros},
                    ylabel = {$||p_{i,exato}-p_i||_\infty$ [$bar$]},
                    legend style={at={(0.95,0.20)}, anchor=east, font=\footnotesize},
                    ymax=10000,
                    ]
                    % \addplot[color=green, solid, thick, mark=*] table [x=var, y=MaxDeltaOdd, col sep=comma] {results_1D_Gauss.csv};
                    \addplot[color=red, solid, thick, mark=*] table [x=var, y=MaxDeltaOddJac, col sep=comma] {results_1D_10k.csv};
                    \addplot[color=black, solid, thick, mark=*] table [x=var, y=MaxDeltaOddGS, col sep=comma] {results_1D_10k.csv};
                    \addplot[color=blue, solid, thick, mark=*] table [x=var, y=MaxDeltaOddSRS08, col sep=comma] {results_1D_10k.csv};
                    \addplot[color=cyan, solid, thick, mark=*] table [x=var, y=MaxDeltaOddSRS12, col sep=comma] {results_1D_10k.csv};
                    \legend{Jacobi, Gauss-Siedel, SRS $\omega = 0.8$, SRS $\omega = 1.2$};
                \end{loglogaxis}
            \end{tikzpicture}
            \caption{Máximo erro absoluto de pressão na resolução de problemas unidimensionais.}
            \label{fig:erropressao10k}
        \end{figure}

        \begin{figure}[hbt!]
            \begin{tikzpicture}
                \begin{loglogaxis}[
                    grid=both,
                    xlabel = {Número de Parâmetros},
                    ylabel = {$||Sw_{i,exato}-Sw_i||_\infty$},
                    legend style={at={(0.40,0.80)}, anchor=east, font=\footnotesize},
                    ymax=10000,
                    ]
                    \addplot[color=green, solid, thick, mark=*] table [x=var, y=MaxDeltaEven, col sep=comma] {results_1D_Gauss.csv};
                    \addplot[color=red, solid, thick, mark=*] table [x=var, y=MaxDeltaEvenJac, col sep=comma] {results_1D_10k.csv};
                    \addplot[color=black, solid, thick, mark=*] table [x=var, y=MaxDeltaEvenGS, col sep=comma] {results_1D_10k.csv};
                    \addplot[color=blue, solid, thick, mark=*] table [x=var, y=MaxDeltaEvenSRS08, col sep=comma] {results_1D_10k.csv};
                    \addplot[color=cyan, solid, thick, mark=*] table [x=var, y=MaxDeltaEvenSRS12, col sep=comma] {results_1D_10k.csv};
                    \legend{Elim.Gauss, Jacobi, Gauss-Siedel, SRS $\omega = 0.8$, SRS $\omega = 1.2$};
                \end{loglogaxis}
            \end{tikzpicture}
            \caption{Máximo erro absoluto de saturação de água na resolução de problemas unidimensionais.}
            \label{fig:errosw10k}
        \end{figure}

        As avaliações foram repetidas para o caso de modelos bidimensionais (Figuras \ref{fig:convergencia2k2d} a \ref{fig:errosw2k2d}). Como o número de parâmetros aumenta consideravelmente, o número máximo de iterações foi de 2 mil. O destaque é o Método SRS com $\omega = 0.8$, que não divergiu nas avaliações feitas. Contudo, todos os métodos iterativos tiveram desempenho muito ruim quando o número de parâmetros aumentou muito. Para os problemas com mais de 500 variáveis o erro máximo na pressão foi de 20 a quase 200 bar (Figura \ref{fig:erropressao2k2d}).

        Um outro efeito interessante é que, para o limite de 2 mil iterações, os métodos iterativos foram mais rápidos que o Método de Eliminação de Gauss quando o sistema de equações tinha mais de 1000 parâmetros (Figura \ref{fig:dt2k2d}). Contudo, este resultado mais rápido dos métodos iterativos não foi aceitável.

        \begin{figure}[hbt!]
            \begin{tikzpicture}
                \begin{loglogaxis}[
                    grid=both,
                    xlabel = {Número de Parâmetros},
                    ylabel = {$\epsilon$},
                    ymax = 2,
                    legend style={at={(0.50,0.80)}, anchor=east, font=\footnotesize},
                    ]
                    \addplot[color=red, solid, thick, mark=*] table [x=var, y=ConvJac, col sep=comma] {results_2D_2k.csv};
                    \addplot[color=black, solid, thick, mark=*] table [x=var, y=ConvGS, col sep=comma] {results_2D_2k.csv};
                    \addplot[color=blue, solid, thick, mark=*] table [x=var, y=ConvSRS08, col sep=comma] {results_2D_2k.csv};
                    \addplot[color=cyan, solid, thick, mark=*] table [x=var, y=ConvSRS12, col sep=comma] {results_2D_2k.csv};
                    \legend{Jacobi, Gauss-Siedel, SRS $\omega = 0.8$, SRS $\omega = 1.2$};
                \end{loglogaxis}
            \end{tikzpicture}
            \caption{Valor da norma de convergência após até duas mil iterações na resolução de problemas bidimensionais.}
            \label{fig:convergencia2k2d}
        \end{figure}

        \begin{figure}[hbt!]
            \begin{tikzpicture}
                \begin{loglogaxis}[
                    grid=both,
                    xlabel = {Número de Parâmetros},
                    ylabel = {Tempo [$10^{-3}s$]},
                    legend style={at={(0.40,0.80)}, anchor=east, font=\footnotesize},
                    ]
                    \addplot[color=green, solid, thick, mark=*] table [x=Parameters, y=Milliseconds, col sep=comma] {results_2D_Gauss.csv};
                    \addplot[color=red, solid, thick, mark=*] table [x=var, y=dtJac, col sep=comma] {results_2D_2k.csv};
                    \addplot[color=black, solid, thick, mark=*] table [x=var, y=dtGS, col sep=comma] {results_2D_2k.csv};
                    \addplot[color=blue, solid, thick, mark=*] table [x=var, y=dtSRS08, col sep=comma] {results_2D_2k.csv};
                    \addplot[color=cyan, solid, thick, mark=*] table [x=var, y=dtSRS12, col sep=comma] {results_2D_2k.csv};
                    \legend{Elim.Gauss, Jacobi, Gauss-Siedel, SRS $\omega = 0.8$, SRS $\omega = 1.2$};
                \end{loglogaxis}
            \end{tikzpicture}
            \caption{Tempo de resolução de problemas unidimensionais.}
            \label{fig:dt2k2d}
        \end{figure}

        \begin{figure}[hbt!]
            \begin{tikzpicture}
                \begin{loglogaxis}[
                    grid=both,
                    xlabel = {Número de Parâmetros},
                    ylabel = {$||p_{i,exato}-p_i||_\infty$ [$bar$]},
                    legend style={at={(0.95,0.30)}, anchor=east, font=\footnotesize},
                    ymax=10000,
                    ]
                    % \addplot[color=green, solid, thick, mark=*] table [x=Parameters, y=MaxDeltaXOdd, col sep=comma] {results_2D_Gauss.csv};
                    \addplot[color=red, solid, thick, mark=*] table [x=var, y=MaxDeltaOddJac, col sep=comma] {results_2D_2k.csv};
                    \addplot[color=black, solid, thick, mark=*] table [x=var, y=MaxDeltaOddGS, col sep=comma] {results_2D_2k.csv};
                    \addplot[color=blue, solid, thick, mark=*] table [x=var, y=MaxDeltaOddSRS08, col sep=comma] {results_2D_2k.csv};
                    \addplot[color=cyan, solid, thick, mark=*] table [x=var, y=MaxDeltaOddSRS12, col sep=comma] {results_2D_2k.csv};
                    \legend{Jacobi, Gauss-Siedel, SRS $\omega = 0.8$, SRS $\omega = 1.2$};
                \end{loglogaxis}
            \end{tikzpicture}
            \caption{Máximo erro absoluto de pressão na resolução de problemas bidimensionais.}
            \label{fig:erropressao2k2d}
        \end{figure}

        \begin{figure}[hbt!]
            \begin{tikzpicture}
                \begin{loglogaxis}[
                    grid=both,
                    xlabel = {Número de Parâmetros},
                    ylabel = {$||Sw_{i,exato}-Sw_i||_\infty$},
                    legend style={at={(0.40,0.80)}, anchor=east, font=\footnotesize},
                    ymax=10000,
                    ]
                    \addplot[color=green, solid, thick, mark=*] table [x=Parameters, y=MaxDeltaXEven, col sep=comma] {results_2D_Gauss.csv};
                    \addplot[color=red, solid, thick, mark=*] table [x=var, y=MaxDeltaEvenJac, col sep=comma] {results_2D_2k.csv};
                    \addplot[color=black, solid, thick, mark=*] table [x=var, y=MaxDeltaEvenGS, col sep=comma] {results_2D_2k.csv};
                    \addplot[color=blue, solid, thick, mark=*] table [x=var, y=MaxDeltaEvenSRS08, col sep=comma] {results_2D_2k.csv};
                    \addplot[color=cyan, solid, thick, mark=*] table [x=var, y=MaxDeltaEvenSRS12, col sep=comma] {results_2D_2k.csv};
                    \legend{Elim.Gauss, Jacobi, Gauss-Siedel, SRS $\omega = 0.8$, SRS $\omega = 1.2$};
                \end{loglogaxis}
            \end{tikzpicture}
            \caption{Máximo erro absoluto de saturação de água na resolução de problemas bidimensionais.}
            \label{fig:errosw2k2d}
        \end{figure}

        O código foi implementado em C++ e em um único arquivo. Pode ser encontrado em \href{https://github.com/TiagoCAAmorim/numerical-methods/blob/main/11_Jacobi_GS/11_Jacobi_GS.cpp}{https://github.com/Tiago CAAmorim/numerical-methods}.

\section{Conclusão}

            Os testes realizados mostram que, entre os métodos testados, apenas o Método de Eliminação de Gauss chega a bons resultados. Mesmo com um incremento no número de iterações e baixo critério de convergência, os métodos iterativos avaliados tivem resultados pobres. Nos casos com um número maior de parâmetros estes métodos não convergiram.

            Como o método da Eliminação de Gauss é computacionalmente muito demandante, é preciso buscar outros métodos de resolução de sistemas de equações para resolver o problema proposto. Uma possibilidade é buscar entre algoritmos que tenham boa performance com matrizes esparsas, como o Método do Gradiente Conjugado.

    % \label{}

%% The Appendices part is started with the command \appendix;
%% appendix sections are then done as normal sections

\appendix

%% \section{}
%% \label{}

%% If you have bibdatabase file and want bibtex to generate the
%% bibitems, please use
%%

\bibliographystyle{elsarticle-num}
\bibliography{refs}

%% else use the following coding to input the bibitems directly in the
%% TeX file.

% \begin{thebibliography}{00}

%% \bibitem{label}
%% Text of bibliographic item

% \bibitem{}

% \end{thebibliography}

% \newpage
% \FloatBarrier
% \section{Código em C}

% O código de ambos métodos foi implementado em um único arquivo. O código é apresentado em duas partes neste documento para facilitar a leitura. O código pode ser encontrado em \href{https://github.com/TiagoCAAmorim/numerical-methods}{https://github.com/TiagoCAAmorim/numerical-methods}.

% \subsection{Método da Bissecção}
% \lstinputlisting[language=C, linerange={1-229}]{./02_newton_raphson.c}

% \subsection{Método de Newton-Raphson}
% \lstinputlisting[language=C, linerange={231-445}]{./02_newton_raphson.c}

% \subsection{Método da Mínima Curvatura}
% \lstinputlisting[language=C, linerange={448-958}]{./02_newton_raphson.c}

\end{document}
\endinput